{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using the NN Ensemble class\n",
    "\n",
    "This is a simple/silly example using an existing NN surrogate of the LCLS injector showing how to set up a NN ensemble in lume-model.\n",
    "\n",
    "The surrogate can be installed from [https://github.com/slaclab/lcls_cu_injector_ml_model](https://github.com/slaclab/lcls_cu_injector_ml_model). **You will need to have the model files installed locally in order to run this notebook**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T12:20:23.809750Z",
     "start_time": "2023-04-26T12:20:21.653781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smiskov/miniconda3/envs/lume-torch-latest/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lume_torch.utils import variables_from_yaml\n",
    "from lume_torch.models import TorchModel\n",
    "from lume_torch.models.ensemble import NNEnsemble\n",
    "from lume_torch.variables import DistributionVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_lcls_model = \"../../../lcls_cu_injector_ml_model/resources/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transformers\n",
    "input_sim_to_nn = torch.load(\n",
    "    path_to_lcls_model + \"input_sim_to_nn.pt\", weights_only=False\n",
    ")\n",
    "output_sim_to_nn = torch.load(\n",
    "    path_to_lcls_model + \"output_sim_to_nn.pt\", weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load in- and output variable specification\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m input_variables, output_variables = \u001b[43mvariables_from_yaml\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_to_lcls_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel/sim_variables.yml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SLAC/lume-torch/lume_torch/utils.py:210\u001b[39m, in \u001b[36mvariables_from_yaml\u001b[39m\u001b[34m(yaml_obj)\u001b[39m\n\u001b[32m    208\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mParsing variables from YAML string\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    209\u001b[39m     yaml_str = yaml_obj\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m config = \u001b[43mdeserialize_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m variables_from_dict(config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SLAC/lume-torch/lume_torch/utils.py:106\u001b[39m, in \u001b[36mdeserialize_variables\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs custom deserialization for in- and output variables.\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \n\u001b[32m    104\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mDeserializing variables\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_variables\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_variables\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    108\u001b[39m         v[key] = [\n\u001b[32m    109\u001b[39m             var_dict | {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: var_name} \u001b[38;5;28;01mfor\u001b[39;00m var_name, var_dict \u001b[38;5;129;01min\u001b[39;00m value.items()\n\u001b[32m    110\u001b[39m         ]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# load in- and output variable specification\n",
    "input_variables, output_variables = variables_from_yaml(\n",
    "    path_to_lcls_model + \"model/sim_variables.yml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example inputs ready for test\n",
    "inputs_small = torch.load(\n",
    "    path_to_lcls_model + \"info/inputs_small.pt\", weights_only=False\n",
    ")\n",
    "outputs_small = torch.load(\n",
    "    path_to_lcls_model + \"info/outputs_small.pt\", weights_only=False\n",
    ")\n",
    "\n",
    "input_dict = {}\n",
    "for i, n in enumerate(input_variables):\n",
    "    input_dict[n.name] = inputs_small[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a wrapper around the model to add some random noise to the outputs\n",
    "\n",
    "Note that without this, since our ensemble is all the same NN, the variance would be zero and the output distribution instantiation would throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLCLSSurrogate(TorchModel):\n",
    "    \"\"\"Dumb class to create noisy/variable output\n",
    "    for the LCLS surrogate model\"\"\"\n",
    "\n",
    "    noise_level: float = 0.01\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _evaluate(self, input_dict):\n",
    "        # Add random noise to output\n",
    "        output_dict = super()._evaluate(input_dict)\n",
    "        noise = np.random.normal(0, self.noise_level)\n",
    "        output_dict_noisy = {n: t + t * noise for n, t in output_dict.items()}\n",
    "        return output_dict_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_model = NoisyLCLSSurrogate(\n",
    "    model=path_to_lcls_model + \"model/model.pt\",\n",
    "    input_variables=input_variables,\n",
    "    output_variables=output_variables,\n",
    "    input_transformers=[input_sim_to_nn],\n",
    "    output_transformers=[output_sim_to_nn],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [noisy_model] * 10\n",
    "ensemble_output_variables = [\n",
    "    DistributionVariable(name=\"sigma_x\"),\n",
    "    DistributionVariable(name=\"sigma_y\"),\n",
    "    DistributionVariable(name=\"sigma_z\"),\n",
    "    DistributionVariable(name=\"norm_emit_x\"),\n",
    "    DistributionVariable(name=\"norm_emit_y\"),\n",
    "]\n",
    "\n",
    "nn_ensemble = NNEnsemble(\n",
    "    models=models_list,\n",
    "    input_variables=input_variables,\n",
    "    output_variables=ensemble_output_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_out = nn_ensemble.evaluate(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ensemble_out.items():\n",
    "    print(\n",
    "        k, v.mean[0], v.variance[0]\n",
    "    )  # example mean/var for first sample of all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example data and predictions\n",
    "nrows, ncols = 3, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 15))\n",
    "for i, output_name in enumerate(nn_ensemble.output_names):\n",
    "    ax_i = ax[i // ncols, i % ncols]\n",
    "    if i < outputs_small.shape[1]:\n",
    "        sort_idx = torch.argsort(outputs_small[:, i])\n",
    "        x_axis = torch.arange(outputs_small.shape[0])\n",
    "        lower = ensemble_out[output_name].mean[sort_idx] - torch.sqrt(\n",
    "            ensemble_out[output_name].variance[sort_idx]\n",
    "        )\n",
    "        upper = ensemble_out[output_name].mean[sort_idx] + torch.sqrt(\n",
    "            ensemble_out[output_name].variance[sort_idx]\n",
    "        )\n",
    "        ax_i.fill_between(\n",
    "            x=x_axis, y1=lower, y2=upper, color=\"C1\", label=\"ensemble predictions\"\n",
    "        )\n",
    "        ax_i.plot(x_axis, outputs_small[sort_idx, i], \"C0x\", label=\"outputs\", alpha=0.5)\n",
    "        ax_i.legend()\n",
    "        ax_i.set_title(output_name)\n",
    "ax[-1, -1].axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
